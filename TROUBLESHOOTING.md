Tipp: Diese Commands sind auch in den Skripten unter ./scripts/ verfÃ¼gbar!


### **3. TROUBLESHOOTING.md - Problembehandlung**
```markdown
# ğŸ”§ Troubleshooting Guide - Solr-Kafka-HA Platform

## ğŸ“‹ Inhalt
- [HÃ¤ufige Probleme](#hÃ¤ufige-probleme)
- [ZooKeeper Probleme](#zookeeper-probleme)
- [Kafka Probleme](#kafka-probleme)
- [Solr Probleme](#solr-probleme)
- [Netzwerk Probleme](#netzwerk-probleme)
- [Performance Probleme](#performance-probleme)
- [Recovery Prozeduren](#recovery-prozeduren)

## ğŸš¨ HÃ„UFIGE PROBLEME

### Pods starten nicht
**Symptome:**
- Pods bleiben im `Pending` oder `CrashLoopBackOff` Status
- `kubectl get pods` zeigt nicht alle 9 Pods als `Running`

**LÃ¶sungen:**
```bash
# 1. Events prÃ¼fen
kubectl get events -n solr-kafka-ha --sort-by='.lastTimestamp'

# 2. Pod Logs anzeigen
kubectl logs <pod-name> -n solr-kafka-ha --previous

# 3. Resource Limits prÃ¼fen
kubectl describe nodes | grep -A 10 "Allocatable"

# 4. Persistent Volume Claims
kubectl get pvc -n solr-kafka-ha

# 5. Neustart versuchen
kubectl delete pod <pod-name> -n solr-kafka-ha



DNS/Netzwerk Probleme
Symptome:

Pods kÃ¶nnen sich nicht gegenseitig erreichen

Service Discovery funktioniert nicht

Connection refused/timeout Fehler

LÃ¶sungen:
# 1. DNS Resolution testen
kubectl run test-dns --image=busybox -it --rm --restart=Never \
  -- nslookup kafka-headless.solr-kafka-ha.svc.cluster.local

# 2. Netzwerk Connectivity testen
./scripts/check-connectivity.sh

# 3. Services und Endpoints prÃ¼fen
kubectl get svc,ep -n solr-kafka-ha

# 4. Network Policies prÃ¼fen
kubectl get networkpolicies -n solr-kafka-ha


ğŸ˜ ZOOKEEPER PROBLEME
ZooKeeper Quorum nicht erreichbar
Symptome:

ruok gibt nicht imok zurÃ¼ck

Kein Leader gewÃ¤hlt

Error: Connection refused oder No route to host

LÃ¶sungen:
# 1. Basis Status prÃ¼fen
for i in {0..2}; do
  echo "zookeeper-$i:" $(kubectl exec -n solr-kafka-ha zookeeper-$i -- echo ruok | nc localhost 2181 2>/dev/null || echo "FAILED")
done

# 2. ZooKeeper Logs anzeigen
kubectl logs -l app=zookeeper -n solr-kafka-ha --tail=100

# 3. ConfigMap prÃ¼fen
kubectl describe configmap zookeeper-config -n solr-kafka-ha

# 4. Persistent Storage prÃ¼fen
kubectl exec -n solr-kafka-ha zookeeper-0 -- ls -la /var/lib/zookeeper/data

# 5. ZooKeeper Ensemble neu starten
kubectl delete pods -l app=zookeeper -n solr-kafka-ha



ZooKeeper Leader Election Probleme
Symptome:

StÃ¤ndiger Leader Wechsel

FOLLOWER Status Ã¤ndert sich nicht zu LEADER

Error: Unable to connect to ZooKeeper

LÃ¶sungen:
# 1. Aktuellen Leader finden
for i in {0..2}; do
  MODE=$(kubectl exec -n solr-kafka-ha zookeeper-$i -- echo stat | nc localhost 2181 2>/dev/null | grep Mode | cut -d: -f2)
  echo "zookeeper-$i: $MODE"
done

# 2. Ensemble GrÃ¶ÃŸe prÃ¼fen (muss ungerade sein)
echo "Ensemble size should be 3,5,7..."

# 3. Netzwerk zwischen ZooKeepers prÃ¼fen
./scripts/test-inter-zookeeper-connectivity.sh

# 4. ZooKeeper Daten lÃ¶schen (Achtung! Datenverlust)
kubectl exec -n solr-kafka-ha zookeeper-0 -- rm -rf /var/lib/zookeeper/data/version-2/*



ğŸš€ KAFKA PROBLEME
Kafka Broker nicht erreichbar
Symptome:

kafka-topics --list schlÃ¤gt fehl

Producer/Consumer kÃ¶nnen nicht verbinden

Error: Broker may not be available

LÃ¶sungen:
# 1. Broker Status prÃ¼fen
for i in {0..2}; do
  kubectl exec -n solr-kafka-ha kafka-$i -- \
    kafka-broker-api-versions --bootstrap-server localhost:9092 2>&1 | \
    head -1 && echo "kafka-$i: OK" || echo "kafka-$i: FAILED"
done

# 2. Kafka Logs anzeigen
kubectl logs -l app=kafka -n solr-kafka-ha --tail=100 | grep -i error

# 3. ZooKeeper Connection prÃ¼fen
kubectl exec -n solr-kafka-ha kafka-0 -- \
  zookeeper-shell zookeeper-0.zookeeper-headless:2181 ls /brokers/ids

# 4. Topic Replication prÃ¼fen
kubectl exec -n solr-kafka-ha kafka-0 -- \
  kafka-topics --bootstrap-server localhost:9092 \
  --describe --topic test-topic

# 5. Kafka neu starten
kubectl delete pods -l app=kafka -n solr-kafka-ha

Kafka Replication Probleme
Symptome:

ISR (In-Sync Replicas) Anzahl zu niedrig

Unterreplikation Warnungen

Data loss nach Broker Failure

LÃ¶sungen:
# 1. Replication Status prÃ¼fen
kubectl exec -n solr-kafka-ha kafka-0 -- \
  kafka-topics --bootstrap-server localhost:9092 \
  --describe --under-replicated-partitions

# 2. Offline Replicas finden
kubectl exec -n solr-kafka-ha kafka-0 -- \
  kafka-topics --bootstrap-server localhost:9092 \
  --describe --unavailable-partitions

# 3. Replication erhÃ¶hen
kubectl exec -n solr-kafka-ha kafka-0 -- \
  kafka-topics --bootstrap-server localhost:9092 \
  --alter --topic test-topic --replication-factor 3

# 4. Partitions neu verteilen
cat > reassign.json << 'EOF'
{"version":1,"partitions":[...]}
EOF
kubectl cp reassign.json solr-kafka-ha/kafka-0:/tmp/
kubectl exec -n solr-kafka-ha kafka-0 -- \
  kafka-reassign-partitions --bootstrap-server localhost:9092 \
  --reassignment-json-file /tmp/reassign.json --execute


ğŸ” SOLR PROBLEME
Solr Cloud nicht erreichbar
Symptome:

Solr UI nicht erreichbar (Port 8983)

Collections kÃ¶nnen nicht erstellt werden

ZooKeeper Connection Fehler

LÃ¶sungen:
# 1. Solr HTTP Status prÃ¼fen
curl -s http://localhost:8983/solr/admin/cores?action=STATUS | jq .

# 2. Solr Logs anzeigen
kubectl logs -l app=solr -n solr-kafka-ha --tail=100

# 3. ZooKeeper Connection prÃ¼fen
kubectl exec -n solr-kafka-ha deployment/solr-standalone -- \
  curl -s "http://localhost:8983/solr/admin/zookeeper/status?wt=json"

# 4. Solr Nodes in ZooKeeper prÃ¼fen
kubectl exec -n solr-kafka-ha zookeeper-0 -- \
  zkCli.sh ls /solr/live_nodes 2>/dev/null

# 5. Solr neu starten
kubectl rollout restart deployment solr-standalone -n solr-kafka-ha


Solr Collection Probleme
Symptome:

Collection kann nicht erstellt werden

Shards nicht verfÃ¼gbar

Replication Fehler

LÃ¶sungen:
# 1. Collection Status prÃ¼fen
curl "http://localhost:8983/solr/admin/collections?action=CLUSTERSTATUS"

# 2. Shard Distribution prÃ¼fen
curl "http://localhost:8983/solr/admin/collections?action=CLUSTERSTATUS&collection=test-collection"

# 3. Collection neu erstellen
curl "http://localhost:8983/solr/admin/collections?action=DELETE&name=test-collection"
curl "http://localhost:8983/solr/admin/collections?action=CREATE&name=test-collection&numShards=2&replicationFactor=3"

# 4. Solr Config prÃ¼fen
kubectl describe configmap solr-config -n solr-kafka-ha


ğŸŒ NETZWERK PROBLEME
Service Discovery Probleme
Symptome:

Headless Services nicht erreichbar

DNS AuflÃ¶sung schlÃ¤gt fehl

Pods kÃ¶nnen sich nicht verbinden

LÃ¶sungen:
# 1. CoreDNS Status prÃ¼fen
kubectl get pods -n kube-system -l k8s-app=kube-dns

# 2. DNS Resolution testen
kubectl run dns-test --image=busybox -it --rm --restart=Never \
  -- nslookup solr.solr-kafka-ha.svc.cluster.local

# 3. Service Endpoints prÃ¼fen
kubectl get endpoints -n solr-kafka-ha

# 4. Network Policies deaktivieren (temporÃ¤r)
kubectl delete networkpolicies --all -n solr-kafka-ha

# 5. Kube-Proxy Status
kubectl get pods -n kube-system -l k8s-app=kube-proxy


Port Connectivity Probleme
Symptome:

Connection refused auf spezifischen Ports

Timeout bei Verbindungsversuchen

Firewall/Network Policy Probleme

LÃ¶sungen:
# 1. Ports von innerhalb testen
kubectl exec -n solr-kafka-ha zookeeper-0 -- \
  nc -zv kafka-0.kafka-headless 9092

# 2. Service Ports prÃ¼fen
kubectl get svc -n solr-kafka-ha -o yaml | grep -A 3 "ports:"

# 3. NodePort/LoadBalancer prÃ¼fen
kubectl describe svc solr -n solr-kafka-ha

# 4. Netzwerk-Tracing
kubectl run netcat --image=busybox -it --rm --restart=Never \
  -- sh -c 'nc -zv solr 8983 && echo "Connection successful"'


âš¡ PERFORMANCE PROBLEME
Hohe Latenz
Symptome:

Langsame Antwortzeiten

Timeouts bei Operationen

High CPU/Memory Usage

LÃ¶sungen:
# 1. Ressourcenverbrauch prÃ¼fen
kubectl top pods -n solr-kafka-ha

# 2. JVM Heap Usage prÃ¼fen (Solr/Kafka)
kubectl exec -n solr-kafka-ha solr-standalone-xxx -- \
  jstat -gc $(pgrep java) 1000 10

# 3. GC AktivitÃ¤t prÃ¼fen
kubectl logs -l app=solr -n solr-kafka-ha | grep -i gc

# 4. Thread Dumps (bei Deadlocks)
kubectl exec -n solr-kafka-ha solr-standalone-xxx -- \
  jstack $(pgrep java) > thread-dump.txt

# 5. Resource Limits erhÃ¶hen
kubectl edit deployment solr-standalone -n solr-kafka-ha


Memory Issues
Symptome:

OOM (Out Of Memory) Errors

High GC Activity

Pod Restarts wegen Memory

LÃ¶sungen:
# 1. Memory Limits anpassen
kubectl set resources deployment solr-standalone \
  --limits=memory=2Gi --requests=memory=1Gi -n solr-kafka-ha

# 2. JVM Heap Settings anpassen
kubectl set env deployment solr-standalone \
  SOLR_HEAP="1g" -n solr-kafka-ha

# 3. Kafka Heap anpassen
kubectl set env deployment kafka \
  KAFKA_HEAP_OPTS="-Xmx2g -Xms2g" -n solr-kafka-ha

# 4. Monitoring aktivieren
kubectl apply -f monitoring/prometheus.yaml



ğŸ› ï¸ RECOVERY PROZEDUREN

Kompletter Cluster Failure
# 1. Alles stoppen
kubectl delete deployments,statefulsets --all -n solr-kafka-ha

# 2. Persistent Volumes lÃ¶schen (Achtung! Datenverlust)
kubectl delete pvc --all -n solr-kafka-ha

# 3. Namespace neu erstellen
kubectl delete namespace solr-kafka-ha
kubectl create namespace solr-kafka-ha

# 4. Neu deployen
./scripts/deploy-ha-platform.sh

# 5. HA Tests durchfÃ¼hren
./scripts/test-ha-platform-complete.sh


Datenverlust Recovery
# 1. Letztes Backup identifizieren
ls -la /backup/solr-kafka-ha/

# 2. ZooKeeper Snapshot wiederherstellen
kubectl cp /backup/zookeeper-snapshot.tar.gz solr-kafka-ha/zookeeper-0:/tmp/
kubectl exec -n solr-kafka-ha zookeeper-0 -- \
  tar xzf /tmp/zookeeper-snapshot.tar.gz -C /var/lib/zookeeper/

# 3. Kafka Topics wiederherstellen
cat /backup/kafka-topics.txt | while read topic; do
  kubectl exec -n solr-kafka-ha kafka-0 -- \
    kafka-topics --bootstrap-server localhost:9092 \
    --create --topic "$topic" --partitions 3 --replication-factor 3
done

# 4. Solr Collections wiederherstellen
curl -X POST "http://localhost:8983/solr/admin/collections?action=RESTORE&name=backup1"


Rolling Update Probleme
# 1. Update stoppen
kubectl rollout pause deployment solr-standalone -n solr-kafka-ha

# 2. Zu vorheriger Version zurÃ¼ck
kubectl rollout undo deployment solr-standalone -n solr-kafka-ha

# 3. Update fortsetzen
kubectl rollout resume deployment solr-standalone -n solr-kafka-ha

# 4. Status prÃ¼fen
kubectl rollout status deployment solr-standalone -n solr-kafka-ha



ğŸ“Š DIAGNOSTIC TOOLS
Health Check Skripte

# Komplette Diagnose
./scripts/diagnose-cluster.sh

# Spezifische Checks
./scripts/check-network.sh
./scripts/check-storage.sh
./scripts/check-security.sh

# Performance Tests
./scripts/performance-test.sh


Log Aggregation

# Alle Logs sammeln
./scripts/collect-logs.sh

# Logs analysieren
./scripts/analyze-logs.sh

# Metrics exportieren
./scripts/export-metrics.sh



ğŸ“ SUPPORT ESCALATION
Bevor Sie Support kontaktieren:
Logs gesammelt: ./scripts/collect-logs.sh

Diagnose durchgefÃ¼hrt: ./scripts/diagnose-cluster.sh

Configuration geprÃ¼ft: kubectl describe <resource>

Events Ã¼berprÃ¼ft: kubectl get events --sort-by='.lastTimestamp'

Reproduction Steps dokumentiert

Wichtige Informationen bereithalten:
Kubernetes Version: kubectl version

Cluster Info: kubectl cluster-info

Node Status: kubectl get nodes -o wide

Namespace Status: kubectl get all -n solr-kafka-ha


### **4. PROJECT-HISTORY.md - Projektverlauf**
```markdown
# ğŸ“œ Project History - Solr-Kafka-HA Platform

## ğŸ¯ ProjektÃ¼bersicht
Dokumentation der Entwicklungsgeschichte, Meilensteine und wichtigen Entscheidungen fÃ¼r die hochverfÃ¼gbare Solr-Kafka-ZooKeeper Plattform.

## ğŸ“… Zeitleiste

### Phase 1: Konzept & Design (Q1 2026)
**Datum:** Februar 2026
**Ziel:** Architekturdesign und Anforderungsanalyse

**Entscheidungen:**
- âœ… 3-Node Architektur fÃ¼r alle Komponenten
- âœ… Kubernetes als Orchestrierungsplattform
- âœ… StatefulSets fÃ¼r ZooKeeper und Kafka
- âœ… Solr Cloud Mode fÃ¼r horizontale Skalierung
- âœ… Replication Factor 3 fÃ¼r Kafka Topics

**Herausforderungen:**
- Identifikation der optimalen Ressourcenlimits
- Netzwerkkonfiguration fÃ¼r Cross-Component Kommunikation
- Persistent Storage Strategie

---

### Phase 2: Basis-Implementierung (Q1 2026)
**Datum:** Februar 2026
**Ziel:** Grundlegende Deployment Skripte und Konfiguration

**Erfolge:**
- âœ… Kubernetes Manifests fÃ¼r ZooKeeper Ensemble
- âœ… Kafka Broker Konfiguration
- âœ… Solr Standalone Deployment
- âœ… Namespace und Service Accounts

**Technische Details:**
- ZooKeeper Version: 3.8.x
- Kafka Version: 3.5.x
- Solr Version: 9.x
- Kubernetes API: v1.28+

---

### Phase 3: HA Testing & Fehlerbehebung (Q1 2026)
**Datum:** Februar 2026
**Ziel:** Testen der HochverfÃ¼gbarkeits-Features

**Test-Ergebnisse:**
| Datum | ZooKeeper | Kafka | Solr | Status |
|-------|-----------|-------|------|--------|
| 2026-02-09 | âš ï¸ Quorum Probleml | âš ï¸ RF Probleme | âœ… Standalone | Issues |
| 2026-02-10 | âœ… HA-ready | âœ… HA-ready | âš ï¸ Standalone | Warnungen |
| 2026-02-10 | âœ… HA-ready | âœ… HA-ready | âœ… Cloud Mode | Produktionsbereit |

**Wichtige Erkenntnisse:**
1. ZooKeeper benÃ¶tigt ungerade Anzahl Nodes (3,5,7...)
2. Kafka benÃ¶tigt min.insync.replicas=2 fÃ¼r HA
3. Solr benÃ¶tigt expliziten Cloud Mode fÃ¼r Multi-Node Betrieb
4. Netzwerk-Connectivity muss zwischen allen Pods gewÃ¤hrleistet sein

---

### Phase 4: HA-Failover Tests (Q1 2026)
**Datum:** Februar 2026
**Ziel:** Automatisches Failover validieren

**ZooKeeper Leader Failover:**
- âœ… Leader Identifikation implementiert
- âœ… Automatische Leader Election getestet
- âœ… Recovery Time: 30 Sekunden
- âœ… Kein Datenverlust bei Leader-Failure

**Kafka Broker Failover:**
- âœ… Broker Failure Simulation
- âœ… Automatische Partition Reassignment
- âœ… Recovery Time: 45 Sekunden
- âœ… ISR bleibt intakt (min.insync.replicas=2)

**Solr Cloud Failover:**
- âœ… ZooKeeper-basierte Service Discovery
- âœ… Live Nodes Management
- âœ… Automatische Shard Recovery
- âœ… Keine Downtime bei Node-Failure

---

### Phase 5: Monitoring & Observability (Q1 2026)
**Datum:** Februar 2026
**Ziel:** Ãœberwachung und Logging einrichten

**Implementiert:**
- âœ… Health-Check Endpoints fÃ¼r alle Komponenten
- âœ… Log Aggregation Ã¼ber kubectl logs
- âœ… Resource Monitoring mit kubectl top
- âœ… Event Tracking

**Geplant (Q2 2026):**
- ğŸ”„ Prometheus Integration
- ğŸ”„ Grafana Dashboards
- ğŸ”„ Centralized Logging (ELK)
- ğŸ”„ Alerting Rules

---

### Phase 6: Production Readiness (Q1 2026)
**Datum:** Februar 2026
**Ziel:** VollstÃ¤ndige Produktionsbereitschaft

**Status: âœ… VOLLSTÃ„NDIG PRODUKTIONSBEREIT**

**Checkliste:**
- [x] 3-Node ZooKeeper Quorum
- [x] 3-Broker Kafka Cluster mit RF=3
- [x] 3-Node Solr Cloud mit Collections
- [x] Cross-Component Connectivity verifiziert
- [x] Failover getestet und dokumentiert
- [x] Backup Strategie definiert
- [x] Troubleshooting Guide erstellt
- [x] Dokumentation komplettiert

**Kennzahlen:**
Performance Metrics (Stand: 2026-02-10):

ZooKeeper Latency: < 5ms

Kafka Throughput: > 100k msgs/sec

Solr Query Latency: < 50ms

System Availability: 99.9% (getestet)




---

## ğŸ† MEILENSTEINE

### âœ… **M1: Grundlegende Infrastruktur** (2026-02-09)
- Namespace erstellt
- Grundlegende Pods deployt
- Basis-Connectivity hergestellt

### âœ… **M2: ZooKeeper HA** (2026-02-10)
- 3-Node Ensemble konfiguriert
- Quorum etabliert
- Leader-Failover funktioniert

### âœ… **M3: Kafka HA** (2026-02-10)
- 3 Broker Cluster
- Replication Factor 3
- Topic mit min.insync.replicas=2

### âœ… **M4: Solr Cloud** (2026-02-10)
- Migration von Standalone zu Cloud Mode
- ZooKeeper Integration
- Collection Management

### âœ… **M5: VollstÃ¤ndige HA** (2026-02-10)
- Alle Komponenten hochverfÃ¼gbar
- Failover getestet
- Produktionsbereitschaft erreicht

---

## ğŸ“ LESSONS LEARNED

### Technische Lektionen:

1. **ZooKeeper Konfiguration**
   - Immer ungerade Anzahl Nodes
   - 2888 vs 3888 Ports verstehen
   - initContainer fÃ¼r korrekte ID-Setzung

2. **Kafka Optimierung**
   - Replication Factor 3 ist Minimum fÃ¼r HA
   - min.insync.replicas=2 verhindert Datenverlust
   - Kopfzeilen Services fÃ¼r stable DNS

3. **Solr Cloud**
   - SOLR_MODE=cloud ist obligatorisch
   - ZK_HOST muss korrekt gesetzt sein
   - Collections brauchen replicationFactor

4. **Kubernetes**
   - StatefulSets fÃ¼r stateful Anwendungen
   - PodDisruptionBudgets fÃ¼r HA
   - Resource Limits fÃ¼r stabile Performance

### Prozess-Lektionen:

1. **Testen**
   - Testskripte schrittweise entwickeln
   - Failover-Szenarien frÃ¼h testen
   - Automatisierte Regressionstests

2. **Dokumentation**
   - Cheatsheets fÃ¼r hÃ¤ufige Tasks
   - Troubleshooting Guide parallel entwickeln
   - Status transparent dokumentieren

3. **Kommunikation**
   - Klare Status-Zusammenfassungen
   - Transparente Issue-Tracking
   - RegelmÃ¤ÃŸige Fortschrittsberichte

---

## ğŸ”® AUSBLICK (Q2 2026)

### Geplante Verbesserungen:

1. **Monitoring & Alerting**
   - Prometheus Operator
   - Grafana Dashboards
   - Alertmanager konfigurieren

2. **Automation**
   - CI/CD Pipeline fÃ¼r Deployments
   - Automatisierte Backups
   - Disaster Recovery Tests

3. **Skalierung**
   - Auto-scaling Policies
   - Performance Optimierung
   - Load Testing

4. **Sicherheit**
   - TLS fÃ¼r alle Komponenten
   - RBAC Policies
   - Secrets Management

---

## ğŸ“Š STATUS ZUSAMMENFASSUNG

**Aktueller Stand: 2026-02-10**


â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PRODUKTIONSBEREIT âœ… â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ğŸŸ¢ ZooKeeper: 3-Node Quorum â”‚
â”‚ ğŸŸ¢ Kafka: 3-Broker HA â”‚
â”‚ ğŸŸ¢ Solr: 3-Node Cloud Mode â”‚
â”‚ ğŸŸ¢ Connectivity: 100% â”‚
â”‚ ğŸŸ¢ Failover: Getestet & OK â”‚
â”‚ ğŸŸ¡ Monitoring: Teilweise â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜


**NÃ¤chster Meilenstein:**
ğŸ”œ **M6: Enterprise Monitoring** - Geplant fÃ¼r MÃ¤rz 2026

---

## ğŸ‘¥ TEAM

- **Architektur & Design:** [Name]
- **Kubernetes Implementation:** [Name]
- **ZooKeeper/Kafka:** [Name]
- **Solr Integration:** [Name]
- **Testing & QA:** [Name]
- **Dokumentation:** [Name]

---

*Dokument aktualisiert: 2026-02-10*
